
- in a virutal env (or not), run `pip install -r requirements.txt` at the project root
- then run the `crawl_spider.py` script with the following args `--headers "inputs/headers.json" --concurrent_requests 1 --urls "inputs/urls.json"`
- you may of course change the args
